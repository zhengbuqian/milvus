// Copyright (C) 2019-2024 Zilliz. All rights reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance
// with the License. You may obtain a copy of the License at
//
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software distributed under the License
// is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
// or implied. See the License for the specific language governing permissions and limitations under the License

#include "scalar_filter_benchmark.h"
#include "segment_data.h"
#include "segment_wrapper.h"
#include "index_wrapper.h"
#include "query_executor.h"
#include "flame_graph_profiler.h"
#include <algorithm>
#include <numeric>
#include <iostream>
#include <fstream>
#include <iomanip>
#include <cmath>
#include <thread>
#include "bench_paths.h"

namespace milvus {
namespace scalar_bench {

// å¤–éƒ¨å…¨å±€å˜é‡å£°æ˜
extern std::string g_current_run_dir;

std::vector<BenchmarkResult>
ScalarFilterBenchmark::RunBenchmark(const BenchmarkConfig& config) {
    std::vector<BenchmarkResult> all_results;

    // ç”Ÿæˆè¿è¡ŒIDï¼ˆå½“å‰æ—¶é—´çš„æ¯«ç§’æ—¶é—´æˆ³ï¼‰
    auto now = std::chrono::system_clock::now();
    auto run_id = std::chrono::duration_cast<std::chrono::milliseconds>(
        now.time_since_epoch()).count();

    std::cout << "Starting Scalar Filter Benchmark..." << std::endl;
    std::cout << "Run ID: " << run_id << std::endl;
    std::cout << "Total configurations: "
              << config.data_configs.size() << " data configs x "
              << config.index_configs.size() << " index configs x "
              << config.expr_templates.size() << " expression templates x "
              << config.query_values.size() << " query values" << std::endl;

    // ç¬¬ä¸€çº§å¾ªç¯ï¼šæ•°æ®é…ç½®
    for (const auto& data_config : config.data_configs) {
        std::cout << "\n========================================" << std::endl;
        std::cout << "Level 1: Data Config - " << data_config.name << std::endl;
        std::cout << "  Size: " << data_config.segment_size
                  << ", Type: " << data_config.data_type
                  << ", Cardinality: " << data_config.cardinality << std::endl;
        std::cout << "========================================" << std::endl;

        // ç”Ÿæˆæ•°æ®ï¼ˆåªç”Ÿæˆä¸€æ¬¡ï¼‰
        auto start_time = std::chrono::high_resolution_clock::now();
        auto segment = GenerateSegment(data_config);
        auto data_gen_time = std::chrono::duration<double, std::milli>(
            std::chrono::high_resolution_clock::now() - start_time).count();

        std::cout << "âœ“ Data generation completed in " << data_gen_time << " ms" << std::endl;

        // ç¬¬äºŒçº§å¾ªç¯ï¼šç´¢å¼•é…ç½®
        for (size_t idx = 0; idx < config.index_configs.size(); ++idx) {
            const auto& index_config = config.index_configs[idx];

            // æ£€æŸ¥ç´¢å¼•å…¼å®¹æ€§
            if (!IsIndexApplicable(index_config, data_config)) {
                std::cout << "  âŠ— Skipping incompatible index: " << index_config.name << std::endl;
                continue;
            }

            std::cout << "\n  ----------------------------------------" << std::endl;
            std::cout << "  Level 2: Index - " << index_config.name << std::endl;
            std::cout << "  ----------------------------------------" << std::endl;

            // å¦‚æœä¸æ˜¯ç¬¬ä¸€ä¸ªç´¢å¼•ï¼Œéœ€è¦å…ˆåˆ é™¤ä¹‹å‰çš„ç´¢å¼•
            if (idx > 0) {
                // ä»segment bundleä¸­è·å–segment wrapper
                auto bundle = segment;
                auto& segment_wrapper = bundle->wrapper;

                // åˆ é™¤fieldå­—æ®µä¸Šçš„ç´¢å¼•
                auto field_id = segment_wrapper->GetFieldId("field");
                segment_wrapper->DropIndex(field_id);
            }

            // æ„å»ºç´¢å¼•
            start_time = std::chrono::high_resolution_clock::now();
            auto index = BuildIndex(segment, index_config);
            auto index_build_time = std::chrono::duration<double, std::milli>(
                std::chrono::high_resolution_clock::now() - start_time).count();

            std::cout << "  âœ“ Index built in " << index_build_time << " ms" << std::endl;

            // ç¬¬ä¸‰çº§å¾ªç¯ï¼šè¡¨è¾¾å¼æ¨¡æ¿ï¼ˆæ¯ä¸ªéƒ½æ˜¯å®Œæ•´çš„ text protoï¼‰
            for (const auto& expr_template : config.expr_templates) {
                // æ£€æŸ¥è¡¨è¾¾å¼é€‚ç”¨æ€§
                if (!IsExpressionApplicable(expr_template, data_config)) {
                    continue;
                }

                std::cout << "    Testing: " << expr_template.name << std::endl;

                // ç”Ÿæˆcase run IDï¼ˆå½“å‰æ—¶é—´çš„æ¯«ç§’æ—¶é—´æˆ³ï¼‰
                auto case_now = std::chrono::system_clock::now();
                auto case_run_id = std::chrono::duration_cast<std::chrono::milliseconds>(
                    case_now.time_since_epoch()).count();

                // ä¸ºè¿™æ¬¡è¿è¡Œåˆ›å»ºä¸“é—¨çš„æ–‡ä»¶å¤¹
                auto base_results_dir = GetResultsDir();
                std::string run_dir = base_results_dir + std::to_string(run_id) + "/";

                // æ‰§è¡ŒåŸºå‡†æµ‹è¯•ï¼ˆç›´æ¥ä½¿ç”¨ text protoï¼‰
                auto result = ExecuteSingleBenchmark(segment, index, expr_template.expr_template,
                                                    config.test_params, case_run_id, run_dir);

                // å¡«å……å…ƒä¿¡æ¯
                result.run_id = run_id;
                result.case_run_id = case_run_id;
                result.data_config_name = data_config.name;
                result.index_config_name = index_config.name;
                result.expr_template_name = expr_template.name;
                result.query_value_name = "";  // ä¸å†éœ€è¦
                result.actual_expression = expr_template.name;  // ä½¿ç”¨æ¨¡æ¿åç§°ä½œä¸ºè¡¨è¾¾å¼æè¿°
                result.expected_selectivity = -1;  // ç”±æŸ¥è¯¢ç»“æœå†³å®š
                result.index_build_time_ms = index_build_time;

                // è¾“å‡ºå³æ—¶ç»“æœ
                std::cout << "      â†’ P50: " << std::fixed << std::setprecision(2) << result.latency_p50_ms << "ms"
                          << ", P99: " << result.latency_p99_ms << "ms"
                          << ", Matched: " << result.matched_rows << "/" << result.total_rows
                          << " (" << result.actual_selectivity * 100 << "%)" << std::endl;

                all_results.push_back(result);
            }
        }

        std::cout << "\nâœ“ Completed all tests for data config: " << data_config.name << std::endl;
    }

    return all_results;
}

void
ScalarFilterBenchmark::GenerateReport(const std::vector<BenchmarkResult>& results) {
    std::cout << "\n============================================" << std::endl;
    std::cout << "Scalar Filter Benchmark Report" << std::endl;
    std::cout << "============================================" << std::endl;
    std::cout << "Total test cases: " << results.size() << std::endl;

    // æ±‡æ€»ç»Ÿè®¡
    if (!results.empty()) {
        // æ‰¾å‡ºæœ€æ…¢å’Œæœ€å¿«çš„æŸ¥è¯¢
        auto slowest = std::max_element(results.begin(), results.end(),
            [](const auto& a, const auto& b) { return a.latency_p99_ms < b.latency_p99_ms; });
        auto fastest = std::min_element(results.begin(), results.end(),
            [](const auto& a, const auto& b) { return a.latency_p99_ms < b.latency_p99_ms; });

        std::cout << "\nPerformance Summary:" << std::endl;
        std::cout << "  Fastest query (P99): " << fastest->latency_p99_ms << "ms"
                  << " (" << fastest->index_config_name << ", " << fastest->actual_expression << ")" << std::endl;
        std::cout << "  Slowest query (P99): " << slowest->latency_p99_ms << "ms"
                  << " (" << slowest->index_config_name << ", " << slowest->actual_expression << ")" << std::endl;
    }

    // å¤åˆ¶ç»“æœå¹¶æ’åºï¼šå…ˆæŒ‰data configï¼Œå†æŒ‰expressionï¼Œæœ€åæŒ‰index
    std::vector<BenchmarkResult> sorted_results = results;
    std::sort(sorted_results.begin(), sorted_results.end(),
        [](const BenchmarkResult& a, const BenchmarkResult& b) {
            // 1. å…ˆæŒ‰ data_config_name æ’åº
            if (a.data_config_name != b.data_config_name) {
                return a.data_config_name < b.data_config_name;
            }
            // 2. å†æŒ‰ expression æ’åº
            if (a.actual_expression != b.actual_expression) {
                return a.actual_expression < b.actual_expression;
            }
            // 3. æœ€åæŒ‰ index æ’åº
            return a.index_config_name < b.index_config_name;
        });

    // è¯¦ç»†ç»“æœè¡¨ï¼ˆæ¯ä¸€è¡Œæ˜¯ä¸€ä¸ªcaseï¼‰
    std::cout << "\nDetailed Results (Run ID: " << (sorted_results.empty() ? 0 : sorted_results[0].run_id) << "):" << std::endl;
    std::cout << std::setw(15) << std::left << "Case ID"
              << std::setw(30) << "Data Config"
              << std::setw(30) << "Expression"
              << std::setw(20) << "Index"
              << std::setw(10) << std::right << "Avg(ms)"
              << std::setw(10) << "P50(ms)"
              << std::setw(10) << "P99(ms)"
              << std::setw(12) << "Selectivity"
              << std::setw(12) << "Memory(MB)" << std::endl;
    std::cout << std::string(159, '-') << std::endl;

    for (const auto& result : sorted_results) {
        std::cout << std::setw(15) << std::left << result.case_run_id
                  << std::setw(30) << result.data_config_name
                  << std::setw(30) << result.actual_expression
                  << std::setw(20) << result.index_config_name
                  << std::setw(10) << std::right << std::fixed << std::setprecision(2) << result.latency_avg_ms
                  << std::setw(10) << result.latency_p50_ms
                  << std::setw(10) << result.latency_p99_ms
                  << std::setw(11) << std::setprecision(1) << result.actual_selectivity * 100 << "%"
                  << std::setw(12) << std::setprecision(1) << result.index_memory_bytes / (1024.0 * 1024.0) << std::endl;
    }

    // ä¸ºè¿™æ¬¡è¿è¡Œåˆ›å»ºä¸“é—¨çš„æ–‡ä»¶å¤¹
    auto base_results_dir = GetResultsDir();
    int64_t run_id = sorted_results.empty() ? 0 : sorted_results[0].run_id;
    std::string run_dir = base_results_dir + std::to_string(run_id) + "/";

    // åˆ›å»ºè¿è¡Œç›®å½•
    std::string mkdir_cmd = "mkdir -p " + run_dir;
    std::system(mkdir_cmd.c_str());

    // è®¾ç½®å½“å‰è¿è¡Œç›®å½•ï¼ˆç”¨äºä¸­æ–­æ—¶æ¸…ç†ï¼‰
    g_current_run_dir = run_dir;

    // ä¿å­˜åˆ°CSVæ–‡ä»¶
    std::string csv_filename = "benchmark_results.csv";
    std::ofstream csv(run_dir + csv_filename);
    csv << "run_id,case_run_id,data_config,expression,index_config,avg_ms,p50_ms,p90_ms,p99_ms,"
        << "matched_rows,total_rows,selectivity,index_build_ms,memory_mb\n";

    for (const auto& result : results) {
        csv << result.run_id << ","
            << result.case_run_id << ","
            << result.data_config_name << ","
            << "\"" << result.actual_expression << "\","
            << result.index_config_name << ","
            << result.latency_avg_ms << ","
            << result.latency_p50_ms << ","
            << result.latency_p90_ms << ","
            << result.latency_p99_ms << ","
            << result.matched_rows << ","
            << result.total_rows << ","
            << result.actual_selectivity << ","
            << result.index_build_time_ms << ","
            << result.index_memory_bytes / (1024.0 * 1024.0) << "\n";
    }
    csv.close();

    std::cout << "\nResults saved to: " << run_dir << csv_filename << std::endl;

    // ä¿å­˜è¿è¡Œæ‘˜è¦åˆ°åŒä¸€æ–‡ä»¶å¤¹
    std::ofstream summary(run_dir + "run_summary.txt");
    summary << "Benchmark Run Summary" << std::endl;
    summary << "=====================" << std::endl;
    summary << "Run ID: " << run_id << std::endl;
    summary << "Total Cases: " << results.size() << std::endl;
    summary << "Start Time: " << run_id << " ms since epoch" << std::endl;

    if (!results.empty()) {
        // æ‰¾å‡ºæœ€æ…¢å’Œæœ€å¿«çš„æŸ¥è¯¢
        auto slowest = std::max_element(results.begin(), results.end(),
            [](const auto& a, const auto& b) { return a.latency_p99_ms < b.latency_p99_ms; });
        auto fastest = std::min_element(results.begin(), results.end(),
            [](const auto& a, const auto& b) { return a.latency_p99_ms < b.latency_p99_ms; });

        summary << "\nPerformance Highlights:" << std::endl;
        summary << "  Fastest query (P99): " << fastest->latency_p99_ms << " ms" << std::endl;
        summary << "    - Config: " << fastest->data_config_name << std::endl;
        summary << "    - Index: " << fastest->index_config_name << std::endl;
        summary << "    - Expression: " << fastest->actual_expression << std::endl;
        summary << "  Slowest query (P99): " << slowest->latency_p99_ms << " ms" << std::endl;
        summary << "    - Config: " << slowest->data_config_name << std::endl;
        summary << "    - Index: " << slowest->index_config_name << std::endl;
        summary << "    - Expression: " << slowest->actual_expression << std::endl;
    }
    summary.close();

    std::cout << "Run summary saved to: " << run_dir << "run_summary.txt" << std::endl;

    // ä¿å­˜é…ç½®ä¿¡æ¯åˆ°åŒä¸€æ–‡ä»¶å¤¹
    std::ofstream config_file(run_dir + "run_config.json");
    config_file << "{" << std::endl;
    config_file << "  \"run_id\": " << run_id << "," << std::endl;
    config_file << "  \"data_configs\": [";

    // è·å–å”¯ä¸€çš„æ•°æ®é…ç½®
    std::set<std::string> unique_data_configs;
    for (const auto& result : results) {
        unique_data_configs.insert(result.data_config_name);
    }
    bool first_data = true;
    for (const auto& config_name : unique_data_configs) {
        if (!first_data) config_file << ", ";
        config_file << "\"" << config_name << "\"";
        first_data = false;
    }
    config_file << "]," << std::endl;

    config_file << "  \"index_configs\": [";
    std::set<std::string> unique_index_configs;
    for (const auto& result : results) {
        unique_index_configs.insert(result.index_config_name);
    }
    bool first_index = true;
    for (const auto& index_name : unique_index_configs) {
        if (!first_index) config_file << ", ";
        config_file << "\"" << index_name << "\"";
        first_index = false;
    }
    config_file << "]," << std::endl;

    config_file << "  \"expressions\": [";
    std::set<std::string> unique_expressions;
    for (const auto& result : results) {
        unique_expressions.insert(result.actual_expression);
    }
    bool first_expr = true;
    for (const auto& expr : unique_expressions) {
        if (!first_expr) config_file << ", ";
        config_file << "\"" << expr << "\"";
        first_expr = false;
    }
    config_file << "]" << std::endl;
    config_file << "}" << std::endl;
    config_file.close();

    std::cout << "Run configuration saved to: " << run_dir << "run_config.json" << std::endl;
    std::cout << "\nğŸ“ All results saved in folder: " << run_dir << std::endl;
}

BenchmarkConfig
ScalarFilterBenchmark::LoadConfig(const std::string& yaml_file) {
    // TODO: å®ç°YAMLé…ç½®åŠ è½½
    BenchmarkConfig config;

    // æš‚æ—¶è¿”å›ç¡¬ç¼–ç çš„æµ‹è¯•é…ç½®
    // æ•°æ®é…ç½®
    config.data_configs.push_back({
        .name = "uniform_int64_1m",
        .segment_size = 1000000,
        .data_type = "INT64",
        .distribution = Distribution::UNIFORM,
        .cardinality = 100000,
        .null_ratio = 0.0
    });

    // ç´¢å¼•é…ç½®
    config.index_configs.push_back({
        .name = "no_index",
        .type = ScalarIndexType::NONE,
        .params = {}
    });

    // è¡¨è¾¾å¼æ¨¡æ¿
    config.expr_templates.push_back({
        .name = "greater_than",
        .expr_template = "field > {value}",
        .type = ExpressionTemplate::Type::COMPARISON
    });

    // æŸ¥è¯¢å€¼
    config.query_values.push_back({
        .name = "selectivity_10p",
        .values = {{"value", 900000}},
        .expected_selectivity = 0.1
    });

    return config;
}

std::shared_ptr<SegmentBundle>
ScalarFilterBenchmark::GenerateSegment(const DataConfig& config) {
    std::cout << "    Generating " << config.segment_size << " rows of "
              << config.data_type << " data..." << std::endl;

    // ä½¿ç”¨çœŸå®çš„æ•°æ®ç”Ÿæˆå™¨ç”Ÿæˆæ•°æ®
    auto segment_data = SegmentDataGenerator::GenerateSegmentData(config);

    // éªŒè¯æ•°æ®
    if (!segment_data->ValidateData()) {
        throw std::runtime_error("Data validation failed for config: " + config.name);
    }

    // åˆ›å»ºçœŸå®çš„Milvus Segment
    auto segment_wrapper = std::make_shared<SegmentWrapper>();
    segment_wrapper->Initialize(config);

    // å°†ç”Ÿæˆçš„æ•°æ®åŠ è½½åˆ°çœŸå®çš„Segmentä¸­
    segment_wrapper->LoadFromSegmentData(*segment_data);

    // æ‰“å°æ•°æ®ç»Ÿè®¡æ‘˜è¦ï¼ˆä»…åœ¨è°ƒè¯•æ¨¡å¼æˆ–å°æ•°æ®é›†æ—¶ï¼‰
    if (config.segment_size <= 100000) {  // 10ä¸‡è¡Œä»¥ä¸‹æ‰æ‰“å°è¯¦ç»†ä¿¡æ¯
        segment_data->PrintSummary();
    } else {
        std::cout << "    Generated " << segment_data->GetRowCount() << " rows, "
                  << "Memory: " << segment_data->GetMemoryBytes() / (1024.0 * 1024.0)
                  << " MB" << std::endl;
    }

    // è¿”å›åŒ…å«segmentå’Œæ•°æ®çš„ç»“æ„
    auto bundle = std::make_shared<SegmentBundle>();
    bundle->wrapper = segment_wrapper;
    bundle->data = segment_data;

    return bundle;
}

std::shared_ptr<IndexBundle>
ScalarFilterBenchmark::BuildIndex(const std::shared_ptr<SegmentBundle>& segment_bundle,
                                   const IndexConfig& config) {
    // ç›´æ¥ä½¿ç”¨segment bundle
    auto bundle = segment_bundle;
    auto& segment_wrapper = bundle->wrapper;

    // åˆ›å»º IndexManagerï¼ˆuse bench_paths helpers for disk pathsï¼‰
    std::string root_path = GetSegmentsDir();
    auto storage_config = gen_local_storage_config(root_path);
    auto chunk_manager = milvus::storage::CreateChunkManager(storage_config);
    IndexManager index_manager(chunk_manager);

    // æ„å»ºå¹¶åŠ è½½ç´¢å¼•
    auto result = index_manager.BuildAndLoadIndex(*segment_wrapper, "field", config);

    // åˆ›å»ºç´¢å¼•ç»“æœbundle
    auto index_bundle = std::make_shared<IndexBundle>();
    index_bundle->wrapper = nullptr;  // æš‚æ—¶è®¾ç½®ä¸ºnullptrï¼Œå› ä¸ºç´¢å¼•å·²ç»åŠ è½½åˆ°segmentä¸­
    index_bundle->config = config;

    if (result.success) {
        std::cout << "      âœ“ Index built in " << std::fixed << std::setprecision(2)
                  << result.build_time_ms << " ms" << std::endl;
    } else {
        std::cout << "      âœ— Index build failed: " << result.error_message << std::endl;
    }

    return index_bundle;
}

BenchmarkResult
ScalarFilterBenchmark::ExecuteSingleBenchmark(const std::shared_ptr<SegmentBundle>& segment,
                                               const std::shared_ptr<IndexBundle>& index,
                                               const std::string& expression,
                                               const TestParams& params,
                                               int64_t case_run_id,
                                               const std::string& results_dir) {
    BenchmarkResult result;
    std::vector<double> latencies;
    std::vector<int64_t> matched_rows_list;
    latencies.reserve(params.test_iterations);
    matched_rows_list.reserve(params.test_iterations);

    // è·å– SegmentWrapper å’Œ Schema
    auto segment_wrapper = segment->wrapper;
    auto schema = segment_wrapper->GetSchema();
    auto sealed_segment = segment_wrapper->GetSealedSegment();

    // åˆ›å»º QueryExecutor
    QueryExecutor executor(schema);

    // é¢„çƒ­
    for (int i = 0; i < params.warmup_iterations; ++i) {
        // æ‰§è¡ŒçœŸå®æŸ¥è¯¢ï¼ˆtext proto æ ¼å¼ï¼‰
        auto query_result = executor.ExecuteQuery(sealed_segment.get(), expression);
        if (!query_result.success && i == 0) {
            // ç¬¬ä¸€æ¬¡å¤±è´¥æ—¶æŠ¥å‘Šé”™è¯¯
            result.error_message = query_result.error_message;
            result.correctness_verified = false;
            return result;
        }
    }

    // æµ‹è¯•æ‰§è¡Œ
    for (int i = 0; i < params.test_iterations; ++i) {
        // æ‰§è¡ŒçœŸå®æŸ¥è¯¢
        auto query_result = executor.ExecuteQuery(sealed_segment.get(), expression);

        if (query_result.success) {
            latencies.push_back(query_result.execution_time_ms);
            matched_rows_list.push_back(query_result.matched_rows);
        } else {
            // è®°å½•é”™è¯¯ä½†ç»§ç»­
            if (result.error_message.empty()) {
                result.error_message = query_result.error_message;
            }
        }
    }

    // å¦‚æœæ²¡æœ‰æˆåŠŸçš„æŸ¥è¯¢ï¼Œè¿”å›é”™è¯¯
    if (latencies.empty()) {
        result.correctness_verified = false;
        if (result.error_message.empty()) {
            result.error_message = "All queries failed";
        }
        return result;
    }

    // è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    result = CalculateStatistics(latencies, matched_rows_list, segment_wrapper->GetRowCount());
    result.correctness_verified = true;

    // å¦‚æœå¯ç”¨äº†ç«ç„°å›¾ç”Ÿæˆä¸”æ²¡æœ‰é”™è¯¯ï¼Œè¿›è¡Œæ€§èƒ½åˆ†æ
    if (params.enable_flame_graph && result.correctness_verified && !results_dir.empty()) {
        // ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨
        std::string mkdir_cmd = "mkdir -p " + results_dir;
        std::system(mkdir_cmd.c_str());

        // åˆ›å»ºç«ç„°å›¾åˆ†æå™¨
        FlameGraphProfiler::Config profiler_config;
        profiler_config.flamegraph_repo_path = params.flamegraph_repo_path;
        profiler_config.profile_duration_seconds = 1.0;  // é‡‡é›†1ç§’
        profiler_config.total_duration_seconds = 1.5;    // æ€»è¿è¡Œ1.5ç§’
        profiler_config.pre_buffer_seconds = 0.25;       // å‰ç½®ç¼“å†²
        profiler_config.post_buffer_seconds = 0.25;      // åç½®ç¼“å†²

        FlameGraphProfiler profiler(profiler_config);

        // éªŒè¯ç¯å¢ƒ
        if (profiler.ValidateEnvironment()) {
            // ç”Ÿæˆç«ç„°å›¾æ–‡ä»¶å
            std::string svg_filename = results_dir + std::to_string(case_run_id) + ".svg";

            // åˆ›å»ºå·¥ä½œè´Ÿè½½å‡½æ•°
            auto workload = [&]() {
                auto query_result = executor.ExecuteQuery(sealed_segment.get(), expression);
            };

            // ç”Ÿæˆcaseåç§°ç”¨äºç«ç„°å›¾æ ‡é¢˜
            std::string case_name = segment->data->GetConfig().name + "_" +
                                  index->config.name + "_" +
                                  expression.substr(0, 50);  // æˆªå–è¡¨è¾¾å¼å‰50å­—ç¬¦

            // æ‰§è¡Œæ€§èƒ½åˆ†æå¹¶ç”Ÿæˆç«ç„°å›¾
            bool profiling_success = profiler.ProfileAndGenerateFlameGraph(
                workload, svg_filename, case_name);

            if (profiling_success) {
                std::cout << "      âœ“ Flame graph generated: " << svg_filename << std::endl;
            } else {
                std::cout << "      âš  Flame graph generation failed: " << profiler.GetLastError() << std::endl;
            }
        } else {
            std::cout << "      âš  Flame graph profiling skipped: " << profiler.GetLastError() << std::endl;
        }
    }

    return result;
}

bool
ScalarFilterBenchmark::IsIndexApplicable(const IndexConfig& index, const DataConfig& data) {
    // æ£€æŸ¥ç´¢å¼•ç±»å‹æ˜¯å¦é€‚ç”¨äºæ•°æ®ç±»å‹
    if (data.data_type == "VARCHAR") {
        // å­—ç¬¦ä¸²ç±»å‹ä¸æ”¯æŒSTL_SORTç´¢å¼•
        return index.type != ScalarIndexType::STL_SORT;
    }
    return true;
}

bool
ScalarFilterBenchmark::IsExpressionApplicable(const ExpressionTemplate& expr, const DataConfig& data) {
    return true;
}


BenchmarkResult
ScalarFilterBenchmark::CalculateStatistics(const std::vector<double>& latencies,
                                            const std::vector<int64_t>& matches,
                                            int64_t total_rows) {
    BenchmarkResult result;

    if (latencies.empty()) {
        return result;
    }

    // æ’åºå»¶è¿Ÿæ•°æ®
    std::vector<double> sorted_latencies = latencies;
    std::sort(sorted_latencies.begin(), sorted_latencies.end());

    // è®¡ç®—ç™¾åˆ†ä½æ•°
    auto percentile = [&sorted_latencies](double p) {
        int index = static_cast<int>(p * (sorted_latencies.size() - 1));
        return sorted_latencies[index];
    };

    result.latency_p50_ms = percentile(0.50);
    result.latency_p90_ms = percentile(0.90);
    result.latency_p99_ms = percentile(0.99);
    result.latency_p999_ms = percentile(0.999);

    // è®¡ç®—å¹³å‡å€¼
    result.latency_avg_ms = std::accumulate(latencies.begin(), latencies.end(), 0.0) / latencies.size();
    result.latency_min_ms = *std::min_element(latencies.begin(), latencies.end());
    result.latency_max_ms = *std::max_element(latencies.begin(), latencies.end());

    // è®¡ç®—QPS
    result.qps = 1000.0 / result.latency_avg_ms;

    // åŒ¹é…ç»Ÿè®¡
    if (!matches.empty()) {
        result.matched_rows = matches.front();  // å‡è®¾æ‰€æœ‰æ‰§è¡Œè¿”å›ç›¸åŒç»“æœ
        result.total_rows = total_rows;
        result.actual_selectivity = static_cast<double>(result.matched_rows) / total_rows;
    }

    // èµ„æºæŒ‡æ ‡ï¼ˆå ä½å€¼ï¼‰
    result.index_memory_bytes = 10 * 1024 * 1024;  // 10MB
    result.exec_memory_peak_bytes = 50 * 1024 * 1024;  // 50MB
    result.cpu_usage_percent = 75.0;

    return result;
}

} // namespace scalar_bench
} // namespace milvus